{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b403f4a-f2a4-4ade-9cf5-9e627c416a77",
   "metadata": {},
   "source": [
    "## Process KuaiRec\n",
    "This notebook simply creates the adjacency list containing the user-video graph as well as the validation and test data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b23e0dc6-b0b3-498c-b55a-8afb6cda9b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import random\n",
    "import itertools\n",
    "import copy\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from scipy.stats import wilcoxon\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn.models import MetaPath2Vec\n",
    "from torch_geometric.nn import MetaPath2Vec\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.index import index2ptr\n",
    "from torch_geometric.typing import EdgeType, NodeType, OptTensor\n",
    "from torch_geometric.utils import sort_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8db2cb1-c7e3-41e4-8d02-fcf6aa8b29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_watch = pd.read_csv('KuaiRec/big_matrix.csv')\n",
    "\n",
    "unique_users = df_watch['user_id'].unique()\n",
    "unique_videos = df_watch['video_id'].unique()\n",
    "\n",
    "df_watch = df_watch[df_watch['watch_ratio'] >= 2].sort_values(['user_id', 'time'])\n",
    "\n",
    "user2idx = {uid: i for i, uid in enumerate(unique_users)}\n",
    "video2idx = {vid: i for i, vid in enumerate(unique_videos)}\n",
    "idx2video = {i: vid for vid, i in video2idx.items()}\n",
    "\n",
    "\n",
    "# Build user->video edge index\n",
    "user_col = df_watch['user_id'].map(user2idx).values\n",
    "video_col = df_watch['video_id'].map(video2idx).values\n",
    "edge_index_uv = np.vstack([user_col, video_col])\n",
    "edge_weight_uv = torch.tensor(df_watch['watch_ratio'].values, dtype=torch.float)\n",
    "\n",
    "df_social = pd.read_csv('KuaiRec/social_network.csv')\n",
    "df_social['friend_list'] = df_social['friend_list'].apply(lambda x: x.strip('[]').split(','))\n",
    "df_social = df_social.explode('friend_list').dropna()\n",
    "df_social['friend_list'] = df_social['friend_list'].astype(int)\n",
    "\n",
    "# Build user-user edge index\n",
    "userA = df_social['user_id'].map(user2idx).values\n",
    "userB = df_social['friend_list'].map(user2idx).values\n",
    "\n",
    "edge_index_uu = np.vstack([userA, userB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "289a583a-4b29-403c-93e9-91e7d498bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "# Add user, video node counts\n",
    "data['user'].num_nodes = len(user2idx)\n",
    "data['video'].num_nodes = len(video2idx)\n",
    "# user->video edges\n",
    "data['user', 'watches', 'video'].edge_index = torch.tensor(edge_index_uv, dtype=torch.long)\n",
    "data['user', 'watches', 'video'].edge_weight = edge_weight_uv\n",
    "# Include reverse edges too:\n",
    "data['video', 'watched_by', 'user'].edge_index = torch.tensor(edge_index_uv[[1, 0], :], dtype=torch.long)\n",
    "data['video', 'watched_by', 'user'].edge_weight = edge_weight_uv\n",
    "data['user', 'follows', 'user'].edge_index = torch.tensor(edge_index_uu, dtype=torch.long)\n",
    "#w2v_dim = model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce3d94a3-c10f-4a6a-bfae-5405758522ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ num_nodes=7176 },\n",
       "  video={ num_nodes=10728 },\n",
       "  (user, watches, video)={\n",
       "    edge_index=[2, 936568],\n",
       "    edge_weight=[936568],\n",
       "  },\n",
       "  (video, watched_by, user)={\n",
       "    edge_index=[2, 936568],\n",
       "    edge_weight=[936568],\n",
       "  },\n",
       "  (user, follows, user)={ edge_index=[2, 670] }\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9217205e-47b9-406f-b1a5-582b5a92a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved adjacency structures to: KuaiRec/adj_data.pkl\n"
     ]
    }
   ],
   "source": [
    "def adjacency(data, save_path):\n",
    "    edge_index_dict = data.edge_index_dict\n",
    "    num_nodes_dict = {}\n",
    "    for keys, edge_index in edge_index_dict.items():\n",
    "        key = keys[0]\n",
    "        N = int(edge_index[0].max() + 1)\n",
    "        num_nodes_dict[key] = max(N, num_nodes_dict.get(key, N))\n",
    "\n",
    "        key = keys[-1]\n",
    "        N = int(edge_index[1].max() + 1)\n",
    "        num_nodes_dict[key] = max(N, num_nodes_dict.get(key, N))\n",
    "\n",
    "    rowptr_dict, col_dict, rowcount_dict = {}, {}, {}\n",
    "    for keys, edge_index in edge_index_dict.items():\n",
    "        sizes = (num_nodes_dict[keys[0]], num_nodes_dict[keys[-1]])\n",
    "        row, col = sort_edge_index(edge_index, num_nodes=max(sizes)).cpu()\n",
    "        rowptr = index2ptr(row, size=sizes[0])\n",
    "        rowptr_dict[keys] = rowptr\n",
    "        col_dict[keys] = col\n",
    "        rowcount_dict[keys] = rowptr[1:] - rowptr[:-1]\n",
    "    \n",
    "    edge_weight_dict = {\n",
    "            ('user','watches','video'): data['user','watches','video'].edge_weight,\n",
    "            ('video','watched_by','user'): data['video','watched_by','user'].edge_weight,\n",
    "            ('user','follows','user'): None,\n",
    "        }\n",
    "\n",
    "    save_dict = {\n",
    "    \"rowptr_dict\": rowptr_dict,\n",
    "    \"col_dict\": col_dict,\n",
    "    \"rowcount_dict\": rowcount_dict,\n",
    "    \"num_nodes_dict\": num_nodes_dict,\n",
    "    \"edge_weight_dict\": edge_weight_dict\n",
    "    }\n",
    "\n",
    "    # Save to disk.\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(save_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"Saved adjacency structures to: {save_path}\")\n",
    "    \n",
    "adjacency(data, save_path=\"KuaiRec/adj_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec786577-64e3-426d-8724-2749ac68580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('KuaiRec/small_matrix.csv')\n",
    "df = df[df['watch_ratio'] >= 2].sort_values(['user_id', 'time']).reset_index(drop=True)\n",
    "df['user_id'] = df['user_id'].map(user2idx)\n",
    "df['video_id'] = df['video_id'].map(video2idx)\n",
    "\n",
    "# Drop any unmapped values (in case of missing keys)\n",
    "#df = df.dropna(subset=['user_id', 'video_id']).astype({'user_id': int, 'video_id': int})\n",
    "val_data = {}\n",
    "test_data = {}\n",
    "\n",
    "for user_id, group in df.groupby('user_id'):\n",
    "    videos = group['video_id'].tolist()\n",
    "    random.shuffle(videos)\n",
    "    split_idx = int(len(videos) * 0.2)  # 20% val, 80% test\n",
    "    val_videos = videos[:split_idx]\n",
    "    tst_videos = videos[split_idx:]\n",
    "\n",
    "    val_data[user_id] = set(val_videos)\n",
    "    test_data[user_id] = set(tst_videos)\n",
    "    \n",
    "with open('KuaiRec/val_data.pkl', 'wb') as f:\n",
    "    pickle.dump(val_data, f)\n",
    "with open('KuaiRec/test_data.pkl', 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "w2v-exp",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "w2v-exp",
   "language": "python",
   "name": "w2v-exp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
