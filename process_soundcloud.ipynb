{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99b1bb6-0792-464a-9066-684bc568d248",
   "metadata": {},
   "source": [
    "## Process SoundCloud\n",
    "This notebook simply processes the large amount of parquet partitions downloaded from GCS into the format needed for training. It uses polars to process the partitions, and additionally created the required adjacency list containing the user-track graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d9ccd8-b314-4838-8faf-907852185103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch import nn, Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1297cfa-2cf3-41c7-98b7-496be4996292",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Process Listener embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73d130c-312b-4a41-9a13-9d057fe735fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 113849050\n"
     ]
    }
   ],
   "source": [
    "total_rows = (\n",
    "        pl.scan_parquet(\"SoundCloud/listener_embeddings/*.parquet\")\n",
    "        .select(pl.len())\n",
    "        .collect(streaming=True)\n",
    "        .item(0, 0)\n",
    "    )\n",
    "print(f\"Total rows: {total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a23b919-358e-4f23-ae13-0282293d5105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved user embeddings and user2idx mapping\n",
      "CPU times: user 1h 1min 16s, sys: 17min 50s, total: 1h 19min 6s\n",
      "Wall time: 1h 57min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time # takes about 1h 35 min with 256GB RAM & 32 vcpu instance (uses 90% of memory)\n",
    "embeddings_df = (\n",
    "    pl.scan_parquet(\"SoundCloud/listener_embeddings/*.parquet\", n_rows=total_rows)\n",
    "    .select([\"user\", \"embedding\"]).collect(streaming=True).iter_slices(3000000)\n",
    ")\n",
    "user_embeddings = np.empty((total_rows, 150), dtype=np.float32)\n",
    "user2idx = {}\n",
    "offset = 0\n",
    "for chunk_num, chunk in enumerate(embeddings_df, start=1):\n",
    "    n_chunk_rows = chunk.shape[0]\n",
    "    embeddings_chunk = np.vstack(chunk[\"embedding\"].to_list())\n",
    "    user_embeddings[offset:offset + n_chunk_rows, :] = embeddings_chunk\n",
    "    user2idx.update(dict(zip(chunk[\"user\"].to_list(), np.arange(offset, offset + n_chunk_rows))))\n",
    "    offset += n_chunk_rows\n",
    "np.save(\"SoundCloud/user_embeddings.npy\", user_embeddings)\n",
    "with open(\"SoundCloud/user2idx.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user2idx, f)\n",
    "del user_embeddings, embeddings_df\n",
    "print(\"Saved user embeddings and user2idx mapping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e27754a-3361-4e3d-ba44-1d2f555cf68b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Process Track embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc5e2d17-46a2-421e-bb72-0e6f95fca512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 25841871\n"
     ]
    }
   ],
   "source": [
    "total_rows = (\n",
    "        pl.scan_parquet(\"SoundCloud/embeddings/*.parquet\")\n",
    "        .select(pl.len())\n",
    "        .collect(streaming=True)\n",
    "        .item(0, 0)\n",
    "    )\n",
    "print(f\"Total rows: {total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c63516-bd6a-4c57-b64a-bccc878b1b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved track embeddings, track2idx, and idx2track mappings\n",
      "CPU times: user 19min 30s, sys: 3min, total: 22min 31s\n",
      "Wall time: 27min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "track_embeddings_df = (\n",
    "    pl.scan_parquet(\"SoundCloud/embeddings/*.parquet\", n_rows=total_rows)\n",
    "    .select([\"track_id\", \"embedding\"]).with_row_index().collect(streaming=True).iter_slices(3000000)\n",
    ")\n",
    "track_embeddings = np.empty((total_rows, 150), dtype=np.float32)\n",
    "track2idx = {}\n",
    "idx2track = {}\n",
    "offset = 0\n",
    "for chunk_num, chunk in enumerate(track_embeddings_df, start=1):\n",
    "    n_chunk_rows = chunk.shape[0]\n",
    "    embeddings_chunk = np.vstack(chunk[\"embedding\"].to_list())\n",
    "    track_embeddings[offset:offset + n_chunk_rows, :] = embeddings_chunk\n",
    "    idx = np.arange(offset, offset + n_chunk_rows)\n",
    "    track2idx.update(dict(zip(chunk[\"track_id\"].to_list(), idx)))\n",
    "    idx2track.update(dict(zip(idx, chunk[\"track_id\"].to_list())))\n",
    "    offset += n_chunk_rows\n",
    "np.save(\"SoundCloud/track_embeddings.npy\", track_embeddings)\n",
    "with open(\"SoundCloud/track2idx.pkl\", \"wb\") as f:\n",
    "    pickle.dump(track2idx, f)\n",
    "with open(\"SoundCloud/idx2track.pkl\", \"wb\") as f:\n",
    "    pickle.dump(idx2track, f)\n",
    "del track_embeddings, idx2track, track_embeddings_df\n",
    "print(\"Saved track embeddings, track2idx, and idx2track mappings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3608098d-4800-4b51-b841-688147345919",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Process follow interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d47de37-f5fa-4790-a182-227a2ec1f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install polars-u64-idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "594d34e2-e51a-4722-9d6b-54fc53c17fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 5448194410\n"
     ]
    }
   ],
   "source": [
    "total_rows = (\n",
    "        pl.scan_parquet(\"SoundCloud/follows_table/*.parquet\")\n",
    "        .select(pl.len())\n",
    "        .collect(streaming=True)\n",
    "        .item(0, 0)\n",
    "    )\n",
    "print(f\"Total rows: {total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba2f688-6d0d-4d26-a26d-9f13e06d455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in user2idx\n",
    "with open(\"SoundCloud/user2idx.pkl\", \"rb\") as f:\n",
    "    user2idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc658bd-a999-4bf5-95ba-58da0396b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "follows_df = (\n",
    "    pl.scan_parquet(\"SoundCloud/follows_table/*.parquet\", n_rows=total_rows)\n",
    "    .select([\"fan\", \"contact\"]).collect(streaming=True).iter_slices(500000000)\n",
    ")\n",
    "print('loaded')\n",
    "chunks_edge = []\n",
    "\n",
    "# Process each chunk efficiently\n",
    "for chunk in follows_df:\n",
    "    # Map user IDs to indices (efficient and parallel)\n",
    "    chunk = chunk.with_columns([\n",
    "        pl.col(\"fan\").replace_strict(user2idx, default=-1).alias(\"fan_idx\"),\n",
    "        pl.col(\"contact\").replace_strict(user2idx, default=-1).alias(\"contact_idx\")\n",
    "    ])\n",
    "    \n",
    "    # Drop rows where any ID is unknown (-1)\n",
    "    chunk = chunk.filter((pl.col(\"fan_idx\") >= 0) & (pl.col(\"contact_idx\") >= 0))\n",
    "\n",
    "    # Convert to NumPy and store\n",
    "    chunks_edge.append(chunk.select([\"fan_idx\", \"contact_idx\"]).to_numpy())\n",
    "    print('chunk')\n",
    "    \n",
    "# Concatenate all valid edges into a final array\n",
    "edge_index_uu = np.concatenate(chunks_edge, axis=0)\n",
    "np.save(\"SoundCloud/edge_index_uu.npy\", edge_index_uu)\n",
    "print(\"Saved edge_index_uu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c074f29-b1bd-44d2-bf35-20a7d06b294f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Process track interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e96b1bb-d5d2-4816-8535-8575e9172250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 3180251027\n"
     ]
    }
   ],
   "source": [
    "total_rows = (\n",
    "        pl.scan_parquet(\"SoundCloud/track_interactions_90_days/*.parquet\")\n",
    "        .select(pl.len())\n",
    "        .collect(streaming=True)\n",
    "        .item(0, 0)\n",
    "    )\n",
    "print(f\"Total rows: {total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcfdf99c-2aea-40cc-b955-2b03e9a8a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in user2idx & track2idx\n",
    "with open(\"SoundCloud/user2idx.pkl\", \"rb\") as f:\n",
    "    user2idx = pickle.load(f)\n",
    "with open(\"SoundCloud/track2idx.pkl\", \"rb\") as f:\n",
    "    track2idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f20f9c3-855c-43ca-8c52-a1f8a49867b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# -------- Get track interaction edge index --------\n",
    "interactions_df = (\n",
    "    pl.scan_parquet(\"SoundCloud/track_interactions_90_days/*.parquet\", n_rows=total_rows)\n",
    "      .select([\"user\", \"track\", \"score\"])\n",
    "      .collect(streaming=True)\n",
    "      .iter_slices(700000000)\n",
    ")\n",
    "print('loaded df')\n",
    "\n",
    "chunks_edge = []\n",
    "chunks_weight = []\n",
    "for chunk in interactions_df:\n",
    "    # Replace user and track values using the provided dictionaries:\n",
    "    chunk = chunk.with_columns([\n",
    "        pl.col(\"user\").replace_strict(user2idx, default=-1).alias(\"user_idx\"),\n",
    "        pl.col(\"track\").replace_strict(track2idx, default=-1).alias(\"track_idx\")\n",
    "    ]).filter((pl.col(\"user_idx\") >= 0) & (pl.col(\"track_idx\") >= 0))\n",
    "\n",
    "    # Select the columns for edge index and convert to NumPy:\n",
    "    chunk_edge = chunk.select([\"user_idx\", \"track_idx\"]).to_numpy()\n",
    "    chunks_edge.append(chunk_edge)\n",
    "    \n",
    "    # Select the score column (as edge weights) and convert to NumPy:\n",
    "    chunk_weight = chunk.select([\"score\"]).to_numpy()\n",
    "    chunks_weight.append(chunk_weight)\n",
    "    print('chunk')\n",
    "\n",
    "# Concatenate all chunks into final arrays:\n",
    "edge_index_ut = np.concatenate(chunks_edge, axis=0)\n",
    "edge_weight_ut = np.concatenate(chunks_weight, axis=0)\n",
    "np.save(\"SoundCloud/edge_index_ut_90.npy\", edge_index_ut)\n",
    "np.save(\"SoundCloud/edge_weight_ut_90.npy\", edge_weight_ut)\n",
    "del edge_index_ut, edge_weight_ut, interactions_df\n",
    "print(\"Saved edge_index_ut, edge_weight_ut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea810249-7c38-45bf-8d6a-f7c587bd7fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 6054214850\n"
     ]
    }
   ],
   "source": [
    "total_rows = (\n",
    "        pl.scan_parquet(\"SoundCloud/track_interactions_180_days/*.parquet\")\n",
    "        .select(pl.len())\n",
    "        .collect(streaming=True)\n",
    "        .item(0, 0)\n",
    "    )\n",
    "print(f\"Total rows: {total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34105b9c-89ce-438a-851c-b5b721add4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded df\n",
      "Saved edge_index_ut, edge_weight_ut\n",
      "CPU times: user 1h 22min 25s, sys: 22min 3s, total: 1h 44min 28s\n",
      "Wall time: 38min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# -------- Get track interaction edge index --------\n",
    "interactions_df = (\n",
    "    pl.scan_parquet(\"SoundCloud/track_interactions_180_days/*.parquet\", n_rows=total_rows)\n",
    "      .select([\"user\", \"track\", \"score\"])\n",
    "      .collect(streaming=True)\n",
    "      .iter_slices(900000000)\n",
    ")\n",
    "print('loaded df')\n",
    "\n",
    "chunks_edge = []\n",
    "chunks_weight = []\n",
    "for chunk in interactions_df:\n",
    "    # Replace user and track values using the provided dictionaries:\n",
    "    chunk = chunk.with_columns([\n",
    "        pl.col(\"user\").replace_strict(user2idx, default=-1).alias(\"user_idx\"),\n",
    "        pl.col(\"track\").replace_strict(track2idx, default=-1).alias(\"track_idx\")\n",
    "    ]).filter((pl.col(\"user_idx\") >= 0) & (pl.col(\"track_idx\") >= 0))\n",
    "    # Select the columns for edge index and convert to NumPy:\n",
    "    chunk_edge = chunk.select([\"user_idx\", \"track_idx\"]).to_numpy()\n",
    "    chunks_edge.append(chunk_edge)\n",
    "    \n",
    "    # Select the score column (as edge weights) and convert to NumPy:\n",
    "    chunk_weight = chunk.select([\"score\"]).to_numpy()\n",
    "    chunks_weight.append(chunk_weight)\n",
    "\n",
    "# Concatenate all chunks into final arrays:\n",
    "edge_index_ut = np.concatenate(chunks_edge, axis=0)\n",
    "edge_weight_ut = np.concatenate(chunks_weight, axis=0)\n",
    "np.save(\"SoundCloud/edge_index_ut_180.npy\", edge_index_ut)\n",
    "np.save(\"SoundCloud/edge_weight_ut_180.npy\", edge_weight_ut)\n",
    "del edge_index_ut, edge_weight_ut, interactions_df\n",
    "print(\"Saved edge_index_ut, edge_weight_ut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc27c22-0b49-49a8-9cb4-7573d709366d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create val and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6497dd4-ceef-4a69-a000-45e286a9c922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 258232772\n"
     ]
    }
   ],
   "source": [
    "total_rows = (\n",
    "        pl.scan_parquet(\"SoundCloud/offline_eval_interactions/*.parquet\")\n",
    "        .select(pl.len())\n",
    "        .collect(streaming=True)\n",
    "        .item(0, 0)\n",
    "    )\n",
    "print(f\"Total rows: {total_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cb65642-b8c9-44cc-a35b-29d4ba89bf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000\n",
      "100000000\n",
      "58232772\n"
     ]
    }
   ],
   "source": [
    "with open(\"SoundCloud/user2idx.pkl\", \"rb\") as f:\n",
    "    user2idx = pickle.load(f)\n",
    "with open(\"SoundCloud/track2idx.pkl\", \"rb\") as f:\n",
    "    track2idx = pickle.load(f)\n",
    "\n",
    "val_ratio = 0.2\n",
    "\n",
    "evaluation_df = (\n",
    "    pl.scan_parquet(\"SoundCloud/offline_eval_interactions/*.parquet\", n_rows=total_rows).select([\"user_id\", \"track_id\"])\n",
    "    .collect(streaming=True).iter_slices(100000000)\n",
    ")\n",
    "\n",
    "val_data = defaultdict(set)\n",
    "test_data = defaultdict(set)\n",
    "offset = 0\n",
    "for chunk_num, chunk in enumerate(evaluation_df, start=1):\n",
    "    n_chunk_rows = chunk.shape[0]\n",
    "    chunk = chunk.with_columns([\n",
    "        pl.col(\"user_id\").map_elements(lambda x: user2idx.get(x, -1), return_dtype=pl.Int64).alias(\"user_idx\"),\n",
    "        pl.col(\"track_id\").map_elements(lambda x: track2idx.get(x, -1), return_dtype=pl.Int64).alias(\"track_idx\"),\n",
    "        pl.Series(\"rnd\", np.random.rand(n_chunk_rows))\n",
    "    ])\n",
    "    val_chunk = chunk.filter((pl.col(\"rnd\") < val_ratio) & (pl.col(\"user_idx\") >= 0) & (pl.col(\"track_idx\") >= 0)).select([\"user_idx\", \"track_idx\"]).group_by(\"user_idx\").agg(pl.col(\"track_idx\"))\n",
    "    test_chunk = chunk.filter((pl.col(\"rnd\") >= val_ratio) & (pl.col(\"user_idx\") >= 0) & (pl.col(\"track_idx\") >= 0)).select([\"user_idx\", \"track_idx\"]).group_by(\"user_idx\").agg(pl.col(\"track_idx\"))\n",
    "    del chunk\n",
    "    val_data.update({u: val_data[u] | set(t) for u, t in zip(val_chunk['user_idx'].to_list(), val_chunk['track_idx'].to_list())})\n",
    "    test_data.update({u: test_data[u] | set(t) for u, t in zip(test_chunk['user_idx'].to_list(), test_chunk['track_idx'].to_list())})\n",
    "    offset += n_chunk_rows\n",
    "    print(n_chunk_rows)\n",
    "\n",
    "with open(\"SoundCloud/val_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_data, f)\n",
    "with open(\"SoundCloud/test_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c3e1a13-8682-4c7e-b024-e58fc2411a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113849049"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"SoundCloud/val_data.pkl\", \"rb\") as f:\n",
    "    val_data = pickle.load(f)\n",
    "max(val_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c767d-cdbd-4b1c-a4a7-a50516e2e20a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Push to GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd3f3d44-f530-4a7b-b037-f4e55016ce24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://SoundCloud/edge_index_ut_180.npy [Content-Type=application/octet-stream]...\n",
      "Copying file://SoundCloud/edge_index_ut_90.npy [Content-Type=application/octet-stream]...\n",
      "Copying file://SoundCloud/edge_index_uu.npy [Content-Type=application/octet-stream]...\n",
      "Copying file://SoundCloud/edge_weight_ut_180.npy [Content-Type=application/octet-stream]...\n",
      "Copying file://SoundCloud/edge_weight_ut_90.npy [Content-Type=application/octet-stream]...\n",
      "Copying file://SoundCloud/user_embeddings.npy [Content-Type=application/octet-stream]...\n",
      "Copying file://SoundCloud/val_data.pkl [Content-Type=application/octet-stream]...\n",
      "Copying file://SoundCloud/track_embeddings.npy [Content-Type=application/octet-stream]...\n",
      "Copying file://SoundCloud/idx2track.pkl [Content-Type=application/octet-stream]...\n",
      "Copying file://SoundCloud/test_data.pkl [Content-Type=application/octet-stream]...\n",
      "Copying file://SoundCloud/track2idx.pkl [Content-Type=application/octet-stream]...\n",
      "Copying file://SoundCloud/user2idx.pkl [Content-Type=application/octet-stream]...\n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_90.npyTA 00:25:08          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_90.npy\n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_90.npy\n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_90.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:23:39          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:24:11          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:34:28          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:31:08          \n",
      "INFO 0207 08:15:41.177650 copy_helper.py] Found 1 existing temporary components to reuse.\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:21:23          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:21:32          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npy\n",
      "Resuming upload for file://SoundCloud/track_embeddings.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:21:55          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/track_embeddings.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/track_embeddings.npy\n",
      "Resuming upload for file://SoundCloud/track_embeddings.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/track_embeddings.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:23:53          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 02:04:02          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:49:22          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:10:56          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:21:09          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:21:20          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:21:50          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:22:11          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:23:00          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:23:52          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:25:04          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npy\n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:26:44          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:25:39          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:27:49          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:23:35          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:19:26          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:20:45          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:18:31          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:18:49          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:19:48          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:19:44          \n",
      "Resuming upload for file://SoundCloud/edge_index_uu.npy/s ETA 00:20:00          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:19:52          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:20:06          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:20:26          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:22:21          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:23:15          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:18:34          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:17:48          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:15:15          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:15:27          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:15:52          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:16:14          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:14:41          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:14:30          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:13:49          \n",
      "Resuming upload for file://SoundCloud/track_embeddings.npyETA 00:14:26          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:14:22          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:14:31          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:14:55          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:15:35          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:13:35          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:14:06          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:12:29          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:11:44          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:11:44          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:10:26          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:10:55          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:11:05          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:12:03          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy\n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:12:31          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:11:26          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy\n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:12:38          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:10:32          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:10:15          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:10:33          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:10:41          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:11:20          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:08:19          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:09:10          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:08:27          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:08:44          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:09:00          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:08:23          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:07:55          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:07:39          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:07:47          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:07:35          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:07:34          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:06:55          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:06:47          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:08:37          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:06:50          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:06:52          \n",
      "Resuming upload for file://SoundCloud/user_embeddings.npy ETA 00:07:27          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:06:10          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:06:04          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:06:01          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:06:35          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:05:27          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:05:49          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:05:48          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:05:52          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:06:00          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:07:02          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npy\n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:05:32          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:05:09          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:05:04          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:06:04          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npyETA 00:04:50          \n",
      "Resuming upload for file://SoundCloud/edge_index_ut_90.npy\n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:04:34          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:04:16          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:04:17          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npy\n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:04:27          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:05:05          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:05:19          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:05:39          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:05:47          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:06:01          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:07:38          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:07:38          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:09:34          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:10:34          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:11:09          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:03:35          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:13:56          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npy\n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:23:12          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:04:04          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:01:11          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:00:46          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npy\n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npy\n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:02:47          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:02:57          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npy\n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:03:02          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:03:30          \n",
      "Resuming upload for file://SoundCloud/edge_weight_ut_180.npyA 00:01:03          \n",
      "\\ [12/12 files][285.5 GiB/285.5 GiB] 100% Done  97.0 MiB/s ETA 00:00:00         \n",
      "Operation completed over 12 objects/285.5 GiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil -o \"GSUtil:parallel_composite_upload_threshold=150M\" -m cp SoundCloud/*.npy SoundCloud/*.pkl gs://sc-reco-stage-sachin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a474ee1c-2ee1-4f47-ba6c-e676d28daaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://sc-reco-stage-sachin/creator_interactions/\n",
      "gs://sc-reco-stage-sachin/embeddings/\n",
      "gs://sc-reco-stage-sachin/follows_table/\n",
      "gs://sc-reco-stage-sachin/listener_embeddings/\n",
      "gs://sc-reco-stage-sachin/offline_eval_interactions/\n",
      "gs://sc-reco-stage-sachin/track_interactions/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://sc-reco-stage-sachin/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffadce3c-9740-44c2-97a4-946758299653",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create Adjacency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de622c4-bdb4-4fed-ae77-f67619074cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.9 s, sys: 13.8 s, total: 1min 9s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get number of nodes\n",
    "with open(\"SoundCloud/user2idx.pkl\", \"rb\") as f:\n",
    "    user2idx = pickle.load(f) # 2.6 Gb\n",
    "with open(\"SoundCloud/track2idx.pkl\", \"rb\") as f:\n",
    "    track2idx = pickle.load(f) # 0.6 Gb\n",
    "num_users = len(user2idx)\n",
    "num_tracks = len(track2idx)\n",
    "del user2idx, track2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "280f274e-725e-4bc5-bdb8-193b5236f403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 184 μs, sys: 47 μs, total: 231 μs\n",
      "Wall time: 235 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Full graph\n",
    "# Requires ~175 Gb RAM\n",
    "# Create graph\n",
    "data = HeteroData()\n",
    "data['user'].num_nodes = num_users\n",
    "data['track'].num_nodes = num_tracks\n",
    "# Add user-track interactions\n",
    "edge_index_ut = np.load('SoundCloud/edge_index_ut_90.npy') # 36 Gb\n",
    "edge_index_ut = edge_index_ut[edge_index_ut[:, 0] < data['user'].num_nodes]\n",
    "data['user', 'listens', 'track'].edge_index = torch.tensor(edge_index_ut, dtype=torch.long)\n",
    "# Include reverse edges too:\n",
    "data['track', 'listened_by', 'user'].edge_index = torch.tensor(edge_index_ut[:, [1,0]], dtype=torch.long)\n",
    "del edge_index_ut\n",
    "# Add edge weights\n",
    "edge_weight_ut = torch.tensor(np.load('SoundCloud/edge_weight_ut_90.npy'), dtype=torch.float32)\n",
    "data['user', 'listens', 'track'].edge_weight = edge_weight_ut\n",
    "data['track', 'listened_by', 'user'].edge_weight = edge_weight_ut\n",
    "del edge_weight_ut\n",
    "# Add user-user interactions\n",
    "edge_index_uu = np.load('SoundCloud/edge_index_uu.npy') # 19 Gb\n",
    "data['user', 'follows', 'user'].edge_index = torch.tensor(edge_index_uu, dtype=torch.long)\n",
    "del edge_index_uu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee8e2db-b6b0-4b35-9d20-99969aa8182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import numba\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def fill_col(src, dst, insertion_ptr, col):\n",
    "    \"\"\"\n",
    "    Numba JIT function:\n",
    "    For each edge i, we look up src[i], find insertion_ptr for that src node,\n",
    "    and place dst[i] in col[pos], then increment insertion_ptr.\n",
    "    \"\"\"\n",
    "    for i in numba.prange(len(src)):\n",
    "        s = src[i]\n",
    "        pos = insertion_ptr[s]\n",
    "        col[pos] = dst[i]\n",
    "        insertion_ptr[s] = pos + 1\n",
    "\n",
    "def build_csr_two_pass_numba(src: np.ndarray, dst: np.ndarray, num_src: int):\n",
    "    \"\"\"\n",
    "    Build (rowptr, col) for edges (src[i], dst[i]) in two passes:\n",
    "      1) Count how many edges each source node has (np.bincount).\n",
    "      2) Prefix sum -> rowptr, then fill col array via fill_col.\n",
    "\n",
    "    Returns:\n",
    "      rowptr: shape [num_src + 1]\n",
    "      col: shape [len(src)]\n",
    "    \"\"\"\n",
    "    # 1) row_count: how many edges each source node has\n",
    "    row_count = np.bincount(src, minlength=num_src)\n",
    "\n",
    "    # 2) rowptr = prefix sum\n",
    "    rowptr = np.zeros(num_src + 1, dtype=np.int64)\n",
    "    np.cumsum(row_count, out=rowptr[1:])\n",
    "\n",
    "    # 3) Build col array\n",
    "    col = np.zeros(len(src), dtype=np.int64)\n",
    "    insertion_ptr = rowptr.copy()\n",
    "\n",
    "    # 4) Fill\n",
    "    fill_col(src, dst, insertion_ptr, col)\n",
    "\n",
    "    return rowptr, col\n",
    "\n",
    "def build_and_save_adjacency_numba(data: HeteroData, save_path: str):\n",
    "    \"\"\"\n",
    "    For each edge_type in data.edge_index_dict,\n",
    "    builds a CSR adjacency (rowptr, col, rowcount) using a two-pass approach\n",
    "    optimized by Numba. Assumes edge_index is shape [E, 2] (i.e., each row is [src, dst]).\n",
    "\n",
    "    Saves adjacency dicts to 'save_path' for quick future loading.\n",
    "    \"\"\"\n",
    "    # Gather node counts for each node type\n",
    "    num_nodes_dict = {}\n",
    "    for node_type in data.node_types:\n",
    "        num_nodes_dict[node_type] = data[node_type].num_nodes\n",
    "\n",
    "    rowptr_dict = {}\n",
    "    col_dict = {}\n",
    "    rowcount_dict = {}\n",
    "\n",
    "    # Iterate over each edge_type in data\n",
    "    for keys, edge_index in data.edge_index_dict.items():\n",
    "        src_type, rel_type, dst_type = keys\n",
    "        src_size = num_nodes_dict[src_type]\n",
    "        dst_size = num_nodes_dict[dst_type]\n",
    "\n",
    "        # edge_index: shape (E, 2)\n",
    "        edge_index_cpu = edge_index.cpu().numpy()  # shape [E, 2]\n",
    "        # src = first column, dst = second column\n",
    "        src = edge_index_cpu[:, 0]\n",
    "        dst = edge_index_cpu[:, 1]\n",
    "\n",
    "        # Build adjacency\n",
    "        rowptr_np, col_np = build_csr_two_pass_numba(src, dst, num_src=src_size)\n",
    "        rowcount_np = rowptr_np[1:] - rowptr_np[:-1]\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        rowptr_t = torch.from_numpy(rowptr_np)\n",
    "        col_t = torch.from_numpy(col_np)\n",
    "        rowcount_t = torch.from_numpy(rowcount_np)\n",
    "\n",
    "        # Store in dict\n",
    "        rowptr_dict[keys] = rowptr_t\n",
    "        col_dict[keys] = col_t\n",
    "        rowcount_dict[keys] = rowcount_t\n",
    "\n",
    "        print(f\"Processed edge type {keys} with {len(src)} edges.\")\n",
    "    edge_weight_dict = {\n",
    "            ('user','listens','track'): data['user','listens','track'].edge_weight,\n",
    "            ('track','listened_by','user'): data['track','listened_by','user'].edge_weight,\n",
    "            ('user','follows','user'): None,\n",
    "    }\n",
    "\n",
    "    # Build final output\n",
    "    save_dict = {\n",
    "        \"rowptr_dict\": rowptr_dict,\n",
    "        \"col_dict\": col_dict,\n",
    "        \"rowcount_dict\": rowcount_dict,\n",
    "        \"num_nodes_dict\": num_nodes_dict,\n",
    "        \"edge_weights_dict\": edge_weight_dict\n",
    "    }\n",
    "\n",
    "    # Save to disk\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        pickle.dump(save_dict, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"Saved adjacency structures (Numba two-pass) to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82bd5c97-aedf-44b0-a5ae-830c9223c614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed edge type ('user', 'listens', 'track') with 2397045181 edges.\n",
      "Processed edge type ('track', 'listened_by', 'user') with 2397045181 edges.\n",
      "Processed edge type ('user', 'follows', 'user') with 1213157842 edges.\n",
      "Saved adjacency structures (Numba two-pass) to: SoundCloud/adj_data_90.pkl\n",
      "CPU times: user 11min 50s, sys: 1min 58s, total: 13min 49s\n",
      "Wall time: 4min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "build_and_save_adjacency_numba(\n",
    "    data,\n",
    "    save_path=\"SoundCloud/adj_data_90.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300baaaa-524e-473e-94f6-fed2f4f2bac2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Sampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e6ea949-6531-4937-a13e-d2cab4fb21a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% Sampled graph\n",
    "data = HeteroData()\n",
    "data['user'].num_nodes = int(num_users*0.1)\n",
    "data['track'].num_nodes = num_tracks\n",
    "# Load data\n",
    "edge_index_ut = np.load('SoundCloud/edge_index_ut_90.npy')  # Shape: [num_edges, 2]\n",
    "edge_weight_ut = np.load('SoundCloud/edge_weight_ut_90.npy')  # Shape: [num_edges]\n",
    "mask = edge_index_ut[:, 0] < data['user'].num_nodes\n",
    "filtered_edge_index_ut = edge_index_ut[mask]\n",
    "filtered_edge_weight_ut = edge_weight_ut[mask]  # Keep only corresponding weights\n",
    "data['user', 'listens', 'track'].edge_index = torch.tensor(filtered_edge_index_ut, dtype=torch.long)\n",
    "data['user', 'listens', 'track'].edge_weight = torch.tensor(filtered_edge_weight_ut, dtype=torch.float32)\n",
    "# Include reverse edges too:\n",
    "data['track', 'listened_by', 'user'].edge_index = torch.tensor(filtered_edge_index_ut[:, [1, 0]], dtype=torch.long)\n",
    "data['track', 'listened_by', 'user'].edge_weight = torch.tensor(filtered_edge_weight_ut, dtype=torch.float32)\n",
    "del edge_index_ut, edge_weight_ut, filtered_edge_index_ut, filtered_edge_weight_ut\n",
    "# Add user-user interactions\n",
    "edge_index_uu = np.load('SoundCloud/edge_index_uu.npy') # 19 Gb\n",
    "mask = (edge_index_uu[:, 0] < data['user'].num_nodes) & (edge_index_uu[:, 1] < data['user'].num_nodes)\n",
    "filtered_edge_index_uu = edge_index_uu[mask]\n",
    "data['user', 'follows', 'user'].edge_index = torch.tensor(filtered_edge_index_uu, dtype=torch.long)\n",
    "del edge_index_uu, filtered_edge_index_uu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53af660-f732-4a3c-b951-af36c1a07fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed edge type ('user', 'listens', 'track') with 239689843 edges.\n",
      "Processed edge type ('track', 'listened_by', 'user') with 239689843 edges.\n",
      "Processed edge type ('user', 'follows', 'user') with 12303491 edges.\n",
      "Saved adjacency structures (Numba two-pass) to: SoundCloud/adj_data_90_sampled.pkl\n",
      "CPU times: user 51.8 s, sys: 10.3 s, total: 1min 2s\n",
      "Wall time: 43.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "build_and_save_adjacency_numba(\n",
    "    data,\n",
    "    save_path=\"SoundCloud/adj_data_90_sampled.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2751101-d6d5-43f3-97c2-908812a80769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampled User embeddings\n",
    "user_embeddings = torch.tensor(np.load('SoundCloud/user_embeddings.npy'), dtype=torch.float32) # 64 Gb\n",
    "user_embeddings_filtered = user_embeddings[:data['user'].num_nodes]\n",
    "np.save(\"SoundCloud/user_embeddings_sampled.npy\", user_embeddings_filtered.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5595c122-d555-4e99-92ee-7db2f95a5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampled users Val and Test set\n",
    "# Load validation & test set (30Gb)\n",
    "with open(\"SoundCloud/val_data.pkl\", \"rb\") as f:\n",
    "    val_data = pickle.load(f)\n",
    "with open(\"SoundCloud/test_data.pkl\", \"rb\") as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d737cc8-4e3e-45e9-8db6-9f9a04b03a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val Users: 12159002, Filtered: 1215355\n",
      "Original Test Users: 17615887, Filtered: 1760029\n"
     ]
    }
   ],
   "source": [
    "def filter_users(data_dict, num_users):\n",
    "    return {int(user): tracks for user, tracks in data_dict.items() if int(user) < int(num_users)}\n",
    "val_data_filtered = filter_users(val_data, data['user'].num_nodes)\n",
    "test_data_filtered = filter_users(test_data, data['user'].num_nodes)\n",
    "print(f\"Original Val Users: {len(val_data)}, Filtered: {len(val_data_filtered)}\")\n",
    "print(f\"Original Test Users: {len(test_data)}, Filtered: {len(test_data_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a56ce7-f1ce-49d3-917f-6b1b3f19cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered data (optional)\n",
    "with open(\"SoundCloud/val_data_sampled.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_data_filtered, f)\n",
    "with open(\"SoundCloud/test_data_sampled.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_data_filtered, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226476ee-be2c-4181-8b51-bac9ddcf3ace",
   "metadata": {},
   "source": [
    "### Filtered Sampled Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0471ca53-c5ed-4f6a-a875-deb5b152563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index_ut = np.load('SoundCloud/edge_index_ut_90.npy')  # Shape: [num_edges, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09fe332-c310-43aa-8dc1-e11b3cb96e88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_weight_ut = np.load('SoundCloud/edge_weight_ut_90.npy')  # Shape: [num_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11479450-4f2c-4daa-a87d-dc3d26bdec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index_uu = np.load('SoundCloud/edge_index_uu.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f08300-d47c-4400-a122-547d50d1675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users with >10 listens: 30615287/113849050 (26.89%)\n"
     ]
    }
   ],
   "source": [
    "# User activity (listens)\n",
    "user_listens = np.bincount(edge_index_ut[:, 0], minlength=num_users)\n",
    "active_users_mask = user_listens > 10  # >10 plays\n",
    "active_users_idx = np.where(active_users_mask)[0]\n",
    "print(f\"Users with >10 listens: {len(active_users_idx)}/{num_users} \"\n",
    "      f\"({len(active_users_idx) / num_users * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8070c433-2ca7-4777-af72-c816d9d5e590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks with >5 listeners: 13033110/25841871 (50.43%)\n"
     ]
    }
   ],
   "source": [
    "track_listeners = np.bincount(edge_index_ut[:, 1], minlength=num_tracks)\n",
    "active_tracks_mask = track_listeners > 5  # >5 listeners\n",
    "active_tracks_idx = np.where(active_tracks_mask)[0]\n",
    "print(f\"Tracks with >5 listeners: {len(active_tracks_idx)}/{num_tracks} \"\n",
    "      f\"({len(active_tracks_idx) / num_tracks * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef9e5721-573b-4fe9-9e44-0bedee71e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_users = int(0.3*len(active_users_idx))  # Sample 30%\n",
    "sampled_users_idx = np.random.choice(active_users_idx, size=target_users, replace=False)\n",
    "sampled_users_mask = np.zeros(num_users, dtype=bool)\n",
    "sampled_users_mask[sampled_users_idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6a9b199-d01d-45d3-9edd-dd633f3168b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut_mask = sampled_users_mask[edge_index_ut[:, 0]] & active_tracks_mask[edge_index_ut[:, 1]]\n",
    "filtered_edge_index_ut = edge_index_ut[ut_mask]\n",
    "filtered_edge_weight_ut = edge_weight_ut[ut_mask]\n",
    "uu_mask = sampled_users_mask[edge_index_uu[:, 0]] & sampled_users_mask[edge_index_uu[:, 1]]\n",
    "filtered_edge_index_uu = edge_index_uu[uu_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5311816b-9c26-41c5-a369-b8c99519a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_old_to_new = {old: new for new, old in enumerate(sorted(sampled_users_idx))}\n",
    "track_old_to_new = {old: new for new, old in enumerate(sorted(active_tracks_idx))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0841cf29-ed87-4c45-a7d0-2b153a6a8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_edge_index_ut[:, 0] = np.vectorize(user_old_to_new.get)(filtered_edge_index_ut[:, 0])\n",
    "filtered_edge_index_ut[:, 1] = np.vectorize(track_old_to_new.get)(filtered_edge_index_ut[:, 1])\n",
    "filtered_edge_index_uu[:, 0] = np.vectorize(user_old_to_new.get)(filtered_edge_index_uu[:, 0])\n",
    "filtered_edge_index_uu[:, 1] = np.vectorize(user_old_to_new.get)(filtered_edge_index_uu[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "951a2102-fbc5-4ae3-977d-69e9d3e9b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "data['user'].num_nodes = len(sampled_users_idx)\n",
    "data['track'].num_nodes = len(active_tracks_idx)\n",
    "data['user', 'listens', 'track'].edge_index = torch.tensor(filtered_edge_index_ut, dtype=torch.long)\n",
    "data['user', 'listens', 'track'].edge_weight = torch.tensor(filtered_edge_weight_ut, dtype=torch.float32)\n",
    "data['track', 'listened_by', 'user'].edge_index = torch.tensor(filtered_edge_index_ut[:, [1, 0]], dtype=torch.long)\n",
    "data['track', 'listened_by', 'user'].edge_weight = torch.tensor(filtered_edge_weight_ut, dtype=torch.float32)\n",
    "data['user', 'follows', 'user'].edge_index = torch.tensor(filtered_edge_index_uu, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ef75e80-a027-4d81-8918-db4140602805",
   "metadata": {},
   "outputs": [],
   "source": [
    "del edge_index_ut, edge_weight_ut, filtered_edge_index_ut, filtered_edge_weight_ut, ut_mask\n",
    "del edge_index_uu, filtered_edge_index_uu, uu_mask, track_listeners, user_listens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66656681-229c-4980-9233-f7ca193726f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed edge type ('user', 'listens', 'track') with 687379887 edges.\n",
      "Processed edge type ('track', 'listened_by', 'user') with 687379887 edges.\n",
      "Processed edge type ('user', 'follows', 'user') with 21620345 edges.\n",
      "Saved adjacency structures (Numba two-pass) to: SoundCloud/adj_data_90_active_sampled.pkl\n"
     ]
    }
   ],
   "source": [
    "build_and_save_adjacency_numba(data, \"SoundCloud/adj_data_90_active_sampled.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19ced637-cd27-4725-820f-8c8518e7701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05fe7239-14fe-48ee-b9eb-d99cecc197b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampled User embeddings\n",
    "user_embeddings = torch.tensor(np.load('SoundCloud/user_embeddings.npy'), dtype=torch.float32) # 64 Gb\n",
    "user_embeddings_filtered = user_embeddings[sampled_users_idx]\n",
    "del user_embeddings\n",
    "np.save(\"SoundCloud/user_embeddings_active_sampled.npy\", user_embeddings_filtered.numpy())\n",
    "del user_embeddings_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70155acd-c545-4d78-b5f1-f31575270cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_embeddings = torch.tensor(np.load('SoundCloud/track_embeddings.npy'), dtype=torch.float32) # 64 Gb\n",
    "track_embeddings_filtered = track_embeddings[active_tracks_idx]\n",
    "del track_embeddings\n",
    "np.save(\"SoundCloud/track_embeddings_active.npy\", track_embeddings_filtered.numpy())\n",
    "del track_embeddings_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f88fb09-cc3a-4696-aa28-fc6beaca0a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"SoundCloud/val_data.pkl\", \"rb\") as f:\n",
    "    val_data = pickle.load(f)\n",
    "with open(\"SoundCloud/test_data.pkl\", \"rb\") as f:\n",
    "    test_data = pickle.load(f)\n",
    "sampled_users_set = set(sampled_users_idx)\n",
    "active_tracks_set = set(active_tracks_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e36530f2-c97f-46f1-a8ae-81c4676edeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_and_filter_data(data_dict, user_map, track_map, sampled_users, active_tracks, min_listens=1):\n",
    "    new_dict = {}\n",
    "    for old_user, old_tracks in data_dict.items():\n",
    "        if old_user in sampled_users:  # Check if user is in sampled set\n",
    "            # Filter and reindex tracks\n",
    "            new_tracks = [track_map[old_track] for old_track in old_tracks if old_track in active_tracks]\n",
    "            if len(new_tracks) >= min_listens:  # Keep only if enough tracks remain\n",
    "                new_user = user_map[old_user]\n",
    "                new_dict[new_user] = new_tracks\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a031272-b00a-4aa6-9ae7-11d13b41bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_filtered = reindex_and_filter_data(\n",
    "    val_data,\n",
    "    user_old_to_new,\n",
    "    track_old_to_new,\n",
    "    sampled_users_set,\n",
    "    active_tracks_set,\n",
    "    min_listens=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2339016c-1a46-4823-a332-3718e5e2c274",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_filtered = reindex_and_filter_data(\n",
    "    test_data,\n",
    "    user_old_to_new,\n",
    "    track_old_to_new,\n",
    "    sampled_users_set,\n",
    "    active_tracks_set,\n",
    "    min_listens=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "853af3f6-768e-4e34-8a09-712743103ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Val Users: 12159002, Filtered: 3160384\n",
      "Original Test Users: 17615887, Filtered: 4325513\n",
      "Total interactions in original validation set: 49693105\n",
      "Total interactions in original test set: 192883774\n",
      "Total interactions in reindexed validation set: 13781882\n",
      "Total interactions in reindexed test set: 53620557\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original Val Users: {len(val_data)}, Filtered: {len(val_data_filtered)}\")\n",
    "print(f\"Original Test Users: {len(test_data)}, Filtered: {len(test_data_filtered)}\")\n",
    "\n",
    "val_interactions_before = sum(len(tracks) for tracks in val_data.values())\n",
    "test_interactions_before = sum(len(tracks) for tracks in test_data.values())\n",
    "\n",
    "print(f\"Total interactions in original validation set: {val_interactions_before}\")\n",
    "print(f\"Total interactions in original test set: {test_interactions_before}\")\n",
    "\n",
    "val_interactions_after = sum(len(tracks) for tracks in val_data_filtered.values())\n",
    "test_interactions_after = sum(len(tracks) for tracks in test_data_filtered.values())\n",
    "print(f\"Total interactions in reindexed validation set: {val_interactions_after}\")\n",
    "print(f\"Total interactions in reindexed test set: {test_interactions_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cff40489-16ae-41bd-8776-42d39bfc5b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"SoundCloud/val_data_active_sampled.pkl\", \"wb\") as f:\n",
    "    pickle.dump(val_data_filtered, f)\n",
    "with open(\"SoundCloud/test_data_active_sampled.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_data_filtered, f)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "w2v-exp",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "w2v-exp",
   "language": "python",
   "name": "w2v-exp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
